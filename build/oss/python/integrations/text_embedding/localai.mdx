---
title: "Localai integration"
description: "Integrate with the Localai embedding model using LangChain Python."
---

<Info>
**`langchain-localai` is a 3rd party integration package for LocalAI. It provides a simple way to use LocalAI services in LangChain.**

The source code is available on [GitHub](https://github.com/mkhludnev/langchain-localai)

</Info>

Let's load the LocalAI Embedding class. In order to use the LocalAI Embedding class, you need to have the LocalAI service hosted somewhere and configure the embedding models. See the documentation at [localai.io/basics/getting_started/index.html](https://localai.io/basics/getting_started/index.html) and [localai.io/features/embeddings/index.html](https://localai.io/features/embeddings/index.html).

```python
pip install -U langchain-localai
```

```python
from langchain_localai import LocalAIEmbeddings

embeddings = LocalAIEmbeddings(
    openai_api_base="http://localhost:8080", model="embedding-model-name"
)
text = "This is a test document."

query_result = embeddings.embed_query(text)
doc_result = embeddings.embed_documents([text])
```

# Legacy `langchain-community` LocalAIEmbeddings documentation

<Warning>
**For proper compatibility, please ensure you are using the `openai` SDK at version **0.x**.**
</Warning>

Let's load the LocalAI Embedding class with embeddings model.

```python
pip install -U langchain-community
```

```python
from langchain_community.embeddings import LocalAIEmbeddings
import os

# if you are behind an explicit proxy, you can use the OPENAI_PROXY environment variable to pass through
os.environ["OPENAI_PROXY"] = "http://proxy.yourcompany.com:8080"

embeddings = LocalAIEmbeddings(
    openai_api_base="http://localhost:8080", model="embedding-model-name"
)

text = "This is a test document."
query_result = embeddings.embed_query(text)
doc_result = embeddings.embed_documents([text])
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/text_embedding/localai.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>

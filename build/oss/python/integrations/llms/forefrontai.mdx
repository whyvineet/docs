---
title: "Forefrontai integration"
description: "Integrate with the Forefrontai LLM using LangChain Python."
---

The `Forefront` platform gives you the ability to fine-tune and use [open-source Large Language Models (LLMs)](https://docs.forefront.ai/get-started/models).

This notebook goes over how to use LangChain with [ForefrontAI](https://www.forefront.ai/).

## Imports

```python
import os

from langchain_classic.chains import LLMChain
from langchain_community.llms import ForefrontAI
from langchain_core.prompts import PromptTemplate
```

## Set the environment API Key

Make sure to get your API key from ForefrontAI. You are given a 5 day free trial to test different models.

```python
# get a new token: https://docs.forefront.ai/forefront/api-reference/authentication

from getpass import getpass

FOREFRONTAI_API_KEY = getpass()
```

```python
os.environ["FOREFRONTAI_API_KEY"] = FOREFRONTAI_API_KEY
```

## Create the ForefrontAI instance

You can specify different parameters such as the model endpoint url, length, temperature, etc. You must provide an endpoint url.

```python
llm = ForefrontAI(endpoint_url="YOUR ENDPOINT URL HERE")
```

## Create a Prompt template

We will create a prompt template for Question and Answer.

```python
template = """Question: {question}

Answer: Let's think step by step."""

prompt = PromptTemplate.from_template(template)
```

## Initiate the LLMChain

```python
llm_chain = LLMChain(prompt=prompt, llm=llm)
```

## Run the LLMChain

Provide a question and run the LLMChain.

```python
question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"

llm_chain.run(question)
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/llms/forefrontai.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>

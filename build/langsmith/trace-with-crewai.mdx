---
title: Trace CrewAI applications
sidebarTitle: CrewAI
---

LangSmith can capture traces generated by [CrewAI](https://github.com/crewAIInc/crewAI) using OpenTelemetry instrumentation. This guide shows you how to automatically capture traces from your CrewAI multi-agent workflows and send them to LangSmith for monitoring and analysis.

## Installation

Install the required packages using your preferred package manager:

<CodeGroup>

```bash pip
pip install langsmith crewai opentelemetry-instrumentation-crewai opentelemetry-instrumentation-openai
```

```bash uv
uv add langsmith crewai opentelemetry-instrumentation-crewai opentelemetry-instrumentation-openai
```

</CodeGroup>

## Setup

### 1. Configure environment variables

Set your [API keys](/langsmith/create-account-api-key) and project name:

```bash
export LANGSMITH_API_KEY=<your_langsmith_api_key>
export LANGSMITH_PROJECT=<your_project_name>
export OPENAI_API_KEY=<your_openai_api_key>
```

### 2. Configure OpenTelemetry integration

In your CrewAI application, configure the LangSmith OpenTelemetry integration along with the CrewAI and OpenAI instrumentors:

```python
from langsmith.integrations.otel import OtelSpanProcessor
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.instrumentation.crewai import CrewAIInstrumentor
from opentelemetry.instrumentation.openai import OpenAIInstrumentor

# Get or create tracer provider
current_provider = trace.get_tracer_provider()
if isinstance(current_provider, TracerProvider):
    tracer_provider = current_provider
else:
    tracer_provider = TracerProvider()
    trace.set_tracer_provider(tracer_provider)

# Add OtelSpanProcessor to the tracer provider
tracer_provider.add_span_processor(OtelSpanProcessor())

# Instrument CrewAI and OpenAI
CrewAIInstrumentor().instrument(tracer_provider=tracer_provider)
OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)
```

### 3. Create and run your CrewAI application

Once configured, your CrewAI application will automatically send traces to LangSmith:

```python
from crewai import Agent, Crew, Task
from crewai.llm import LLM
from langsmith.integrations.otel import OtelSpanProcessor
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.instrumentation.crewai import CrewAIInstrumentor
from opentelemetry.instrumentation.openai import OpenAIInstrumentor

# Configure OpenTelemetry
current_provider = trace.get_tracer_provider()
if isinstance(current_provider, TracerProvider):
    tracer_provider = current_provider
else:
    tracer_provider = TracerProvider()
    trace.set_tracer_provider(tracer_provider)

tracer_provider.add_span_processor(OtelSpanProcessor())

# Instrument CrewAI and OpenAI
CrewAIInstrumentor().instrument(tracer_provider=tracer_provider)
OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)

# Define your agent
llm = LLM(model="gpt-4o-mini")

coder = Agent(
    role="Software developer",
    goal="Write clear, concise code on demand",
    backstory="An expert coder with a keen eye for software trends.",
    verbose=True,
    llm=llm,
)

# Define your task
task = Task(
    description="Write a Python function that checks if a number is prime.",
    expected_output="A clear and concise Python function with documentation.",
    agent=coder,
)

# Create and run the crew
crew = Crew(
    agents=[coder],
    tasks=[task],
    verbose=True,
)

def run_crew():
    result = crew.kickoff()
    return result

if __name__ == "__main__":
    output = run_crew()
    print(output)
```

## Advanced usage

### Custom metadata and tags

You can add custom metadata to your traces by setting span attributes:

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

def run_crew_with_metadata():
    with tracer.start_as_current_span("crewai_workflow") as span:
        span.set_attribute("langsmith.metadata.crew_type", "code_generation")
        span.set_attribute("langsmith.metadata.agent_count", "1")
        span.set_attribute("langsmith.span.tags", "crewai,code-generation")

        result = crew.kickoff()
        return result
```

### Combining with other instrumentors

You can combine CrewAI instrumentation with other OpenTelemetry instrumentors:

```python
from opentelemetry.instrumentation.crewai import CrewAIInstrumentor
from opentelemetry.instrumentation.openai import OpenAIInstrumentor

# Initialize multiple instrumentors
CrewAIInstrumentor().instrument(tracer_provider=tracer_provider)
OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)
```

## Resources

- [CrewAI documentation](https://docs.crewai.com/)
- [LangSmith OpenTelemetry guide](/langsmith/trace-with-opentelemetry)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/trace-with-crewai.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>

---
title: Trace Microsoft Agent Framework applications
sidebarTitle: Microsoft Agent Framework
---

LangSmith can capture traces generated by [Microsoft Agent Framework](https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview) using its built-in OpenTelemetry instrumentation. This guide shows you how to automatically capture traces from your Microsoft Agent Framework agents and send them to LangSmith for monitoring and analysis.

## Installation

Install the required packages:

<CodeGroup>

```bash pip
pip install agent-framework opentelemetry-exporter-otlp-proto-http
```

```bash uv
uv add agent-framework opentelemetry-exporter-otlp-proto-http
```

</CodeGroup>

## Setup

### 1. Configure environment variables

Enable OpenTelemetry instrumentation of the agent and set the OpenTelemetry environment variables to point to the LangSmith OTEL endpoint:

```bash
export ENABLE_INSTRUMENTATION=true
export OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
export OTEL_EXPORTER_OTLP_ENDPOINT=https://api.smith.langchain.com/otel/v1/traces
export OTEL_EXPORTER_OTLP_HEADERS="x-api-key=<your_langsmith_api_key>,Langsmith-Project=<your_project_name>"
```

### 2. Enable OpenTelemetry in your application

In your Microsoft Agent Framework application, enable OpenTelemetry tracing using the built-in `configure_otel_providers` function:

```python
from agent_framework.observability import configure_otel_providers

# Enable OpenTelemetry tracing
configure_otel_providers(enable_sensitive_data=True)
```

<Note>
Setting `enable_sensitive_data=True` allows capturing input and output content in traces. Set to `False` if you want to exclude sensitive data from traces.
</Note>

### 3. Create and run your agent

Once configured, your Microsoft Agent Framework agents will automatically send traces to LangSmith:

```python
from agent_framework import ChatAgent
from agent_framework.observability import configure_otel_providers
from agent_framework.openai import OpenAIChatClient

# Enable OpenTelemetry tracing
configure_otel_providers(enable_sensitive_data=True)


agent = ChatAgent(
    chat_client=OpenAIChatClient(model_id="gpt-4o"),
)

result = await agent.run("What's the the capital of Bavaria?")
print(result.text)
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/trace-with-microsoft-agent-framework.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>

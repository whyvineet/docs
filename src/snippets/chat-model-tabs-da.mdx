<Tabs>
    <Tab title="OpenAI">
        ðŸ‘‰ Read the [OpenAI chat model integration docs](/oss/python/integrations/chat/openai/)

        ```shell
        pip install -U "langchain[openai]"
        ```

        <CodeGroup>
            ```python default parameters
            import os
            from deepagents import create_deep_agent

            os.environ["OPENAI_API_KEY"] = "sk-..."

            agent = create_deep_agent(model="openai:gpt-5.2")
            # this calls init_chat_model for the specified model with default parameters
            # to use specific modele parameters, use init_chat_model directly
            ```
            ```python init_chat_model
            import os
            from langchain.chat_models import init_chat_model
            from deepagents import create_deep_agent

            os.environ["OPENAI_API_KEY"] = "sk-..."

            model = init_chat_model(model="openai:gpt-4.1")
            agent = create_deep_agent(model=model)
            ```
            ```python Model Class
            import os
            from langchain_openai import ChatOpenAI
            from deepagents import create_deep_agent

            os.environ["OPENAI_API_KEY"] = "sk-..."

            model = ChatOpenAI(model="gpt-4.1")
            agent = create_deep_agent(model=model)
            ```
        </CodeGroup>
    </Tab>
    <Tab title="Anthropic">
        ðŸ‘‰ Read the [Anthropic chat model integration docs](/oss/python/integrations/chat/anthropic/)
        ```shell
        pip install -U "langchain[anthropic]"
        ```

        <CodeGroup>
            ```python default parameters
            import os
            from deepagents import create_deep_agent

            os.environ["ANTHROPIC_API_KEY"] = "sk-..."

            agent = create_deep_agent(model="claude-sonnet-4-5-20250929")
            # this calls init_chat_model for the specified model with default parameters
            # to use specific modele parameters, use init_chat_model directly
            ```
            ```python init_chat_model
            import os
            from langchain.chat_models import init_chat_model
            from deepagents import create_deep_agent

            os.environ["ANTHROPIC_API_KEY"] = "sk-..."

            model = init_chat_model(model="claude-sonnet-4-5-20250929")
            agent = create_deep_agent(model=model)
            ```
            ```python Model Class
            import os
            from langchain_anthropic import ChatAnthropic
            from deepagents import create_deep_agent

            os.environ["ANTHROPIC_API_KEY"] = "sk-..."

            model = ChatAnthropic(model="claude-sonnet-4-5-20250929")
            agent = create_deep_agent(model=model)
            ```
        </CodeGroup>
    </Tab>
    <Tab title="Azure">
        ðŸ‘‰ Read the [Azure chat model integration docs](/oss/python/integrations/chat/azure_chat_openai/)
        ```shell
        pip install -U "langchain[openai]"
        ```

        <CodeGroup>
            ```python default parameters
            import os
            from deepagents import create_deep_agent

            os.environ["AZURE_OPENAI_API_KEY"] = "..."
            os.environ["AZURE_OPENAI_ENDPOINT"] = "..."
            os.environ["OPENAI_API_VERSION"] = "2025-03-01-preview"

            agent = create_deep_agent(model="azure_openai:gpt-4.1")
            # this calls init_chat_model for the specified model with default parameters
            # to use specific modele parameters, use init_chat_model directly
            ```
            ```python init_chat_model
            import os
            from langchain.chat_models import init_chat_model
            from deepagents import create_deep_agent

            os.environ["AZURE_OPENAI_API_KEY"] = "..."
            os.environ["AZURE_OPENAI_ENDPOINT"] = "..."
            os.environ["OPENAI_API_VERSION"] = "2025-03-01-preview"

            model = init_chat_model(
                model="azure_openai:gpt-4.1",
                azure_deployment=os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"],
            )
            agent = create_deep_agent(model=model)
            ```
            ```python Model Class
            import os
            from langchain_openai import AzureChatOpenAI
            from deepagents import create_deep_agent

            os.environ["AZURE_OPENAI_API_KEY"] = "..."
            os.environ["AZURE_OPENAI_ENDPOINT"] = "..."
            os.environ["OPENAI_API_VERSION"] = "2025-03-01-preview"

            model = AzureChatOpenAI(
                model="gpt-4.1",
                azure_deployment=os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"],
            )
            agent = create_deep_agent(model=model)
            ```
        </CodeGroup>
    </Tab>
    <Tab title="Google Gemini">
        ðŸ‘‰ Read the [Google GenAI chat model integration docs](/oss/python/integrations/chat/google_generative_ai/)
        ```shell
        pip install -U "langchain[google-genai]"
        ```

        <CodeGroup>
            ```python default parameters
            import os
            from deepagents import create_deep_agent

            os.environ["GOOGLE_API_KEY"] = "..."

            agent = create_deep_agent(model="google_genai:gemini-2.5-flash-lite")
            # this calls init_chat_model for the specified model with default parameters
            # to use specific modele parameters, use init_chat_model directly
            ```
            ```python init_chat_model
            import os
            from langchain.chat_models import init_chat_model
            from deepagents import create_deep_agent

            os.environ["GOOGLE_API_KEY"] = "..."

            model = init_chat_model(model="google_genai:gemini-2.5-flash-lite")
            agent = create_deep_agent(model=model)
            ```
            ```python Model Class
            import os
            from langchain_google_genai import ChatGoogleGenerativeAI
            from deepagents import create_deep_agent

            os.environ["GOOGLE_API_KEY"] = "..."

            model = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite")
            agent = create_deep_agent(model=model)
            ```
        </CodeGroup>
    </Tab>
    <Tab title="AWS Bedrock">
        ðŸ‘‰ Read the [AWS Bedrock chat model integration docs](/oss/python/integrations/chat/bedrock/)
        ```shell
        pip install -U "langchain[aws]"
        ```

        <CodeGroup>
            ```python default parameters
            from deepagents import create_deep_agent

            # Follow the steps here to configure your credentials:
            # https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html

            agent = create_deep_agent(
                model="anthropic.claude-3-5-sonnet-20240620-v1:0",
                model_provider="bedrock_converse",
            )
            # this calls init_chat_model for the specified model with default parameters
            # to use specific modele parameters, use init_chat_model directly
            ```
            ```python init_chat_model
            from langchain.chat_models import init_chat_model
            from deepagents import create_deep_agent

            # Follow the steps here to configure your credentials:
            # https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html

            model = init_chat_model(
                model="anthropic.claude-3-5-sonnet-20240620-v1:0",
                model_provider="bedrock_converse",
            )
            agent = create_deep_agent(model=model)
            ```
            ```python Model Class
            from langchain_aws import ChatBedrock
            from deepagents import create_deep_agent

            # Follow the steps here to configure your credentials:
            # https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html

            model = ChatBedrock(model="anthropic.claude-3-5-sonnet-20240620-v1:0")
            agent = create_deep_agent(model=model)
            ```
        </CodeGroup>
    </Tab>
    <Tab title="HuggingFace">
        ðŸ‘‰ Read the [HuggingFace chat model integration docs](/oss/python/integrations/chat/huggingface/)

        ```shell
        pip install -U "langchain[huggingface]"
        ```

        <CodeGroup>
            ```python default parameters
            import os
            from deepagents import create_deep_agent

            os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_..."

            agent = create_deep_agent(
                model="microsoft/Phi-3-mini-4k-instruct",
                model_provider="huggingface",
                temperature=0.7,
                max_tokens=1024,
            )
            # this calls init_chat_model for the specified model with default parameters
            # to use specific modele parameters, use init_chat_model directly
            ```
            ```python init_chat_model
            import os
            from langchain.chat_models import init_chat_model
            from deepagents import create_deep_agent

            os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_..."

            model = init_chat_model(
                model="microsoft/Phi-3-mini-4k-instruct",
                model_provider="huggingface",
                temperature=0.7,
                max_tokens=1024,
            )
            agent = create_deep_agent(model=model)
            ```

            ```python Model Class
            import os
            from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint
            from deepagents import create_deep_agent

            os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_..."

            llm = HuggingFaceEndpoint(
                repo_id="microsoft/Phi-3-mini-4k-instruct",
                temperature=0.7,
                max_length=1024,
            )
            model = ChatHuggingFace(llm=llm)
            agent = create_deep_agent(model=model)
            ```
        </CodeGroup>
    </Tab>
</Tabs>
